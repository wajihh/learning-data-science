{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSWO6DOw0IRPlK2WI7Ahj0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wajihh/learning-data-science/blob/master/vae_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variational Auto Encoder\n",
        "Below is an example of a Python project demonstrating the use of Variational Autoencoders (VAEs) with KL divergence and transfer learning. We will use the MNIST dataset for simplicity, but the concepts can be extended to other datasets and applications.\n",
        "\n",
        "## Project Overview\n",
        "Load and Preprocess Data: Load the MNIST dataset and preprocess it.\n",
        "Build and Train a VAE: Construct a Variational Autoencoder, train it on the MNIST dataset, and demonstrate the use of KL divergence in the loss function.\n",
        "Transfer Learning: Fine-tune the pre-trained VAE on a smaller subset of the MNIST dataset."
      ],
      "metadata": {
        "id": "2HjQdOxR0rJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Load and pre process data\n"
      ],
      "metadata": {
        "id": "XVNQsqKc0vRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy matplotlib tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gH_Zcpu1wu3",
        "outputId": "616a3bac-45a2-4805-a710-4ea645803b0d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
        "\n",
        "print(\"Training data shape:\", x_train.shape)\n",
        "print(\"Testing data shape:\", x_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3dQ8Xqj1nbF",
        "outputId": "b4e7da5a-d7bd-43c1-c7ea-6b14b0892f8a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Training data shape: (60000, 28, 28, 1)\n",
            "Testing data shape: (10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Build and Train Data"
      ],
      "metadata": {
        "id": "lAirXIti2PZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE model parameters\n",
        "input_shape = (28, 28, 1)\n",
        "batch_size = 128\n",
        "latent_dim = 2\n",
        "epochs = 50\n",
        "\n",
        "# Encoder\n",
        "inputs = Input(shape=input_shape, name='encoder_input')\n",
        "x = Flatten()(inputs)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
        "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
        "\n",
        "# Sampling function\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "# Use reparameterization trick to push the sampling out as input\n",
        "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
        "\n",
        "# Decoder\n",
        "decoder_input = Input(shape=(latent_dim,), name='z_sampling')\n",
        "x = Dense(256, activation='relu')(decoder_input)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(np.prod(input_shape), activation='sigmoid')(x)\n",
        "outputs = Reshape(input_shape)(x)\n",
        "\n",
        "# Instantiate encoder and decoder models\n",
        "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "decoder = Model(decoder_input, outputs, name='decoder')\n",
        "\n",
        "# Instantiate VAE model\n",
        "outputs = decoder(encoder(inputs)[2])\n",
        "vae = Model(inputs, outputs, name='vae')\n",
        "\n",
        "# Define VAE loss\n",
        "reconstruction_loss = binary_crossentropy(K.flatten(inputs), K.flatten(outputs)) * np.prod(input_shape)\n",
        "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam')\n",
        "vae.summary()\n",
        "\n",
        "# Train VAE\n",
        "vae.fit(x_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, None))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UA_YQ592N4G",
        "outputId": "61f712a8-440f-48f0-e002-589157e4ca40"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vae\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)  [(None, 28, 28, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " encoder (Functional)        [(None, 2),                  534276    ['encoder_input[0][0]']       \n",
            "                              (None, 2),                                                          \n",
            "                              (None, 2)]                                                          \n",
            "                                                                                                  \n",
            " decoder (Functional)        (None, 28, 28, 1)            534544    ['encoder[0][2]']             \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 784)                  0         ['encoder_input[0][0]']       \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 512)                  401920    ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 256)                  131328    ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " z_log_var (Dense)           (None, 2)                    514       ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " z_mean (Dense)              (None, 2)                    514       ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " tf.reshape (TFOpLambda)     (None,)                      0         ['encoder_input[0][0]']       \n",
            "                                                                                                  \n",
            " tf.reshape_1 (TFOpLambda)   (None,)                      0         ['decoder[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOp  (None, 2)                    0         ['z_log_var[0][0]']           \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " tf.math.square (TFOpLambda  (None, 2)                    0         ['z_mean[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.cast (TFOpLambda)        (None,)                      0         ['tf.reshape[0][0]']          \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor (TFOp  (None,)                      0         ['tf.reshape_1[0][0]']        \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " tf.math.subtract (TFOpLamb  (None, 2)                    0         ['tf.__operators__.add[0][0]',\n",
            " da)                                                                 'tf.math.square[0][0]']      \n",
            "                                                                                                  \n",
            " tf.math.exp (TFOpLambda)    (None, 2)                    0         ['z_log_var[0][0]']           \n",
            "                                                                                                  \n",
            " tf.keras.backend.binary_cr  (None,)                      0         ['tf.cast[0][0]',             \n",
            " ossentropy (TFOpLambda)                                             'tf.convert_to_tensor[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.subtract_1 (TFOpLa  (None, 2)                    0         ['tf.math.subtract[0][0]',    \n",
            " mbda)                                                               'tf.math.exp[0][0]']         \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean (TFOpL  ()                           0         ['tf.keras.backend.binary_cros\n",
            " ambda)                                                             sentropy[0][0]']              \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum (TFOpLa  (None,)                      0         ['tf.math.subtract_1[0][0]']  \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLamb  ()                           0         ['tf.math.reduce_mean[0][0]'] \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_1 (TFOpLa  (None,)                      0         ['tf.math.reduce_sum[0][0]']  \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TF  (None,)                      0         ['tf.math.multiply[0][0]',    \n",
            " OpLambda)                                                           'tf.math.multiply_1[0][0]']  \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_1 (TFO  ()                           0         ['tf.__operators__.add_1[0][0]\n",
            " pLambda)                                                           ']                            \n",
            "                                                                                                  \n",
            " add_loss (AddLoss)          ()                           0         ['tf.math.reduce_mean_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1068820 (4.08 MB)\n",
            "Trainable params: 1068820 (4.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "469/469 [==============================] - 23s 43ms/step - loss: 187.6927 - val_loss: 166.4347\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 22s 47ms/step - loss: 161.7219 - val_loss: 158.0217\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 156.0479 - val_loss: 154.5353\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 153.0544 - val_loss: 151.7920\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 151.0180 - val_loss: 149.9686\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 149.4449 - val_loss: 149.6984\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 148.2291 - val_loss: 147.9560\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 18s 39ms/step - loss: 146.8896 - val_loss: 146.6682\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 21s 44ms/step - loss: 146.0002 - val_loss: 146.2758\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 18s 39ms/step - loss: 145.1907 - val_loss: 145.6063\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 144.6601 - val_loss: 144.9166\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - 22s 46ms/step - loss: 144.0160 - val_loss: 144.4851\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - 18s 39ms/step - loss: 143.4181 - val_loss: 143.9088\n",
            "Epoch 14/50\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 142.8531 - val_loss: 143.5660\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 142.4309 - val_loss: 143.1131\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 142.1294 - val_loss: 142.8724\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 141.6798 - val_loss: 142.7980\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 141.4117 - val_loss: 142.0280\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 141.0086 - val_loss: 142.0159\n",
            "Epoch 20/50\n",
            "469/469 [==============================] - 18s 39ms/step - loss: 140.7523 - val_loss: 141.7396\n",
            "Epoch 21/50\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 140.5094 - val_loss: 141.4947\n",
            "Epoch 22/50\n",
            "469/469 [==============================] - 21s 46ms/step - loss: 140.2237 - val_loss: 141.4866\n",
            "Epoch 23/50\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 139.9302 - val_loss: 141.3839\n",
            "Epoch 24/50\n",
            "469/469 [==============================] - 21s 44ms/step - loss: 139.7327 - val_loss: 140.8482\n",
            "Epoch 25/50\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 139.4746 - val_loss: 140.8819\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 139.6423 - val_loss: 140.5072\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - 18s 39ms/step - loss: 139.1754 - val_loss: 140.2532\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 138.9975 - val_loss: 140.4589\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 138.7703 - val_loss: 140.2951\n",
            "Epoch 30/50\n",
            "469/469 [==============================] - 18s 39ms/step - loss: 138.5259 - val_loss: 140.2764\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - 18s 39ms/step - loss: 138.2091 - val_loss: 140.0771\n",
            "Epoch 32/50\n",
            "469/469 [==============================] - 24s 52ms/step - loss: 138.2629 - val_loss: 139.6788\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - 18s 39ms/step - loss: 138.0791 - val_loss: 139.7893\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - 20s 44ms/step - loss: 137.8320 - val_loss: 140.2146\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - 21s 44ms/step - loss: 137.6779 - val_loss: 139.6622\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 137.6604 - val_loss: 139.7126\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - 21s 44ms/step - loss: 137.5915 - val_loss: 139.1180\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - 18s 39ms/step - loss: 137.5047 - val_loss: 139.2513\n",
            "Epoch 39/50\n",
            "469/469 [==============================] - 21s 44ms/step - loss: 137.2804 - val_loss: 139.6601\n",
            "Epoch 40/50\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 137.6036 - val_loss: 139.3591\n",
            "Epoch 41/50\n",
            "469/469 [==============================] - 22s 47ms/step - loss: 136.9606 - val_loss: 139.1502\n",
            "Epoch 42/50\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 136.8841 - val_loss: 139.1740\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - 18s 39ms/step - loss: 136.8907 - val_loss: 139.5359\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 136.8318 - val_loss: 139.1916\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - 20s 44ms/step - loss: 136.5936 - val_loss: 139.5273\n",
            "Epoch 46/50\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 136.3563 - val_loss: 138.7832\n",
            "Epoch 47/50\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 136.2307 - val_loss: 138.6974\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - 18s 39ms/step - loss: 136.2321 - val_loss: 138.4671\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 136.0795 - val_loss: 138.7670\n",
            "Epoch 50/50\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 136.2911 - val_loss: 138.4793\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a0558d5ac20>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Transfer Learning"
      ],
      "metadata": {
        "id": "tv64H4mK6kUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuning on a smaller subset of MNIST\n",
        "(x_train_small, _), (x_test_small, _) = mnist.load_data()\n",
        "x_train_small = x_train_small[:1000].astype('float32') / 255.\n",
        "x_test_small = x_test_small[:100].astype('float32') / 255.\n",
        "x_train_small = np.reshape(x_train_small, (len(x_train_small), 28, 28, 1))\n",
        "x_test_small = np.reshape(x_test_small, (len(x_test_small), 28, 28, 1))\n",
        "\n",
        "# Freeze the encoder layers except the last layer\n",
        "for layer in encoder.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Recompile the VAE with the new settings\n",
        "vae.compile(optimizer='adam')\n",
        "\n",
        "# Fine-tune the VAE\n",
        "vae.fit(x_train_small, epochs=epochs, batch_size=batch_size, validation_data=(x_test_small, None))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXQZpomj6yEX",
        "outputId": "be1b7d3b-011d-425a-ce36-c2b3e7b5ebb5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "8/8 [==============================] - 1s 57ms/step - loss: 130.4320 - val_loss: 134.5598\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 128.7712 - val_loss: 135.1102\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 127.7387 - val_loss: 134.5947\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 127.1738 - val_loss: 135.0526\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 127.0248 - val_loss: 134.6309\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 126.5335 - val_loss: 135.2468\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 126.5086 - val_loss: 135.2575\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 125.9718 - val_loss: 134.7601\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 125.7828 - val_loss: 135.6358\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 125.6848 - val_loss: 135.7076\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 125.5006 - val_loss: 135.4041\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 125.5317 - val_loss: 136.0643\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 125.1258 - val_loss: 135.9083\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 125.0075 - val_loss: 135.6510\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 124.8312 - val_loss: 136.1519\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 124.7105 - val_loss: 136.2472\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 124.6200 - val_loss: 136.2819\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 124.6213 - val_loss: 137.1362\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 124.3895 - val_loss: 136.2243\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 124.0590 - val_loss: 136.2967\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 124.2461 - val_loss: 136.7649\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 124.1935 - val_loss: 136.7272\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 124.0973 - val_loss: 136.8852\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 124.0694 - val_loss: 136.7245\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 123.6820 - val_loss: 137.3049\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 123.6641 - val_loss: 137.1157\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 123.3951 - val_loss: 137.1871\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 123.6830 - val_loss: 137.4137\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 123.2974 - val_loss: 137.0928\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 123.5733 - val_loss: 137.8256\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 123.3800 - val_loss: 137.2335\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 122.9912 - val_loss: 137.6691\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 123.3143 - val_loss: 138.0761\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 123.0602 - val_loss: 137.4586\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 123.1670 - val_loss: 138.0162\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 122.8662 - val_loss: 137.7528\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 122.9926 - val_loss: 137.7117\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 122.7841 - val_loss: 138.0164\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 122.6369 - val_loss: 138.4760\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 122.6441 - val_loss: 138.2796\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 122.4464 - val_loss: 138.8508\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 122.4412 - val_loss: 138.3284\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 122.4376 - val_loss: 138.8907\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 122.6347 - val_loss: 138.6150\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 122.6317 - val_loss: 138.1189\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 122.3325 - val_loss: 138.2388\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 122.2852 - val_loss: 138.1241\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 122.0461 - val_loss: 138.6346\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 121.9637 - val_loss: 138.7053\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 122.2418 - val_loss: 139.0404\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a0558f1f970>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detailed Explanation\n",
        "Data Loading and Preprocessing:\n",
        "\n",
        "We load the MNIST dataset and normalize it to the range [0, 1].\n",
        "The data is reshaped to include a channel dimension, which is required for Keras.\n",
        "VAE Construction:\n",
        "\n",
        "The encoder part of the VAE compresses the input image to a lower-dimensional latent space.\n",
        "The decoder part reconstructs the image from the latent space.\n",
        "The sampling function applies the reparameterization trick, which is crucial for backpropagation through the stochastic nodes.\n",
        "The VAE loss is composed of the reconstruction loss and the KL divergence. The reconstruction loss measures how well the VAE can reconstruct the input, while the KL divergence regularizes the latent space to follow a standard normal distribution.\n",
        "Transfer Learning:\n",
        "\n",
        "We load a smaller subset of the MNIST dataset.\n",
        "We freeze the layers of the encoder (except the last layer) to retain the learned features from the pre-trained model.\n",
        "We recompile the VAE and fine-tune it on the smaller dataset, adjusting the latent space for the new data."
      ],
      "metadata": {
        "id": "IMFNj6wt7BsC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Compare Samples"
      ],
      "metadata": {
        "id": "yPzws4i98Wz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_results(models, data, batch_size=128, model_name=\"vae\"):\n",
        "    encoder, decoder = models\n",
        "    x_test = data\n",
        "\n",
        "    # Encode and decode the test data\n",
        "    z_mean, _, _ = encoder.predict(x_test, batch_size=batch_size)\n",
        "    x_decoded = decoder.predict(z_mean, batch_size=batch_size)\n",
        "\n",
        "    # Plot the results\n",
        "    plt.figure(figsize=(18, 4))\n",
        "    for i in range(10):\n",
        "        # Original images\n",
        "        ax = plt.subplot(3, 10, i + 1)\n",
        "        plt.imshow(x_test[i].reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        # Reconstructed images from step 2\n",
        "        ax = plt.subplot(3, 10, i + 1 + 10)\n",
        "        plt.imshow(x_decoded_step2[i].reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        # Reconstructed images from step 3\n",
        "        ax = plt.subplot(3, 10, i + 1 + 20)\n",
        "        plt.imshow(x_decoded_step3[i].reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "    plt.show()\n",
        "\n",
        "# Generate reconstructions\n",
        "x_decoded_step2 = vae.predict(x_test, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune the model and generate new reconstructions\n",
        "vae.compile(optimizer='adam')\n",
        "vae.fit(x_train_small, epochs=epochs, batch_size=batch_size, validation_data=(x_test_small, None))\n",
        "x_decoded_step3 = vae.predict(x_test, batch_size=batch_size)\n",
        "\n",
        "# Plot the results\n",
        "plot_results((encoder, decoder), x_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mJ9JOJE-8eP6",
        "outputId": "8f271732-6a8a-4b07-ef63-b1de517a128d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 9ms/step\n",
            "Epoch 1/50\n",
            "8/8 [==============================] - 2s 80ms/step - loss: 121.4829 - val_loss: 142.7283\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 120.6374 - val_loss: 142.4269\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 120.6234 - val_loss: 141.8679\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 120.2734 - val_loss: 142.1903\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 120.2285 - val_loss: 141.5419\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 120.2419 - val_loss: 142.1394\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 120.0852 - val_loss: 142.9181\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 120.0414 - val_loss: 141.7273\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 120.0088 - val_loss: 142.3913\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 119.8985 - val_loss: 141.6329\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 119.9258 - val_loss: 141.6542\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 119.9673 - val_loss: 142.0921\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 119.9444 - val_loss: 141.8385\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 119.7020 - val_loss: 142.4916\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 119.8932 - val_loss: 142.3503\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 119.6888 - val_loss: 142.9378\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 119.7131 - val_loss: 143.2195\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 119.6671 - val_loss: 142.7578\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 119.4643 - val_loss: 141.8908\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 119.8884 - val_loss: 142.6125\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 119.6372 - val_loss: 143.4001\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 119.6348 - val_loss: 143.2848\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 119.5488 - val_loss: 142.4975\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 119.6688 - val_loss: 143.2225\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 119.4588 - val_loss: 141.9265\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 119.5475 - val_loss: 142.1786\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 119.4965 - val_loss: 142.3084\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 119.3719 - val_loss: 142.7088\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 119.5857 - val_loss: 142.0788\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 119.6417 - val_loss: 142.9110\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 119.5276 - val_loss: 142.4687\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 119.3711 - val_loss: 142.5397\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 119.2302 - val_loss: 143.0662\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 119.5050 - val_loss: 142.4857\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 119.4122 - val_loss: 143.4741\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 119.3442 - val_loss: 142.3905\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 119.3612 - val_loss: 142.3500\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 119.5111 - val_loss: 143.2192\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 119.1914 - val_loss: 143.1703\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 119.0979 - val_loss: 143.0936\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 119.1392 - val_loss: 143.6357\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 118.9956 - val_loss: 143.4608\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 119.0389 - val_loss: 142.9804\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 119.1486 - val_loss: 143.2688\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 119.1535 - val_loss: 144.3185\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 119.2438 - val_loss: 143.2992\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 119.0792 - val_loss: 143.7436\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 119.0996 - val_loss: 143.6055\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 118.9574 - val_loss: 143.7823\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 119.0538 - val_loss: 144.2233\n",
            "79/79 [==============================] - 1s 8ms/step\n",
            "79/79 [==============================] - 0s 5ms/step\n",
            "79/79 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x400 with 30 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the Losses\n",
        "The reduction in loss from 136 to 122 during fine-tuning indicates that the model has improved in terms of reconstruction quality on the smaller dataset. This suggests that the transfer learning process has effectively adapted the pre-trained VAE to the new, smaller dataset, capturing its specific features better.\n",
        "\n",
        "Code to Compare Samples\n",
        "To visually compare the samples is provided in step 4, we'll plot the original images, the reconstructed images from the model trained in step 2, and the reconstructed images from the fine-tuned model in step 3.\n",
        "Detailed Explanation\n",
        "Data Encoding and Decoding:\n",
        "\n",
        "We encode and decode the test data using the encoder and decoder to get the reconstructed images from both the initial and fine-tuned models.\n",
        "Plotting the Results:\n",
        "\n",
        "We plot three rows of images:\n",
        "The first row shows the original images.\n",
        "The second row shows the reconstructed images from the model trained in step 2.\n",
        "The third row shows the reconstructed images from the fine-tuned model in step 3.\n",
        "Visualization:\n",
        "\n",
        "This visual comparison helps us see the improvements in the reconstruction quality after fine-tuning. Ideally, the images in the third row should look more similar to the original images compared to those in the second row.\n",
        "Running the Code\n",
        "To run this code, ensure you have executed the initial VAE training and fine-tuning steps correctly. This script assumes you have already completed those steps and have the necessary models (encoder, decoder, vae) and data (x_test, x_train_small, x_test_small) in memory.\n",
        "\n",
        "If executed correctly, you should see a plot comparing the original images, the reconstructed images after initial training, and the reconstructed images after fine-tuning, allowing you to visually assess the improvements.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x5xc_jFV9dPB"
      }
    }
  ]
}